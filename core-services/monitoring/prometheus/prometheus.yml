# Prometheus Configuration for ALPR Monitoring Stack
# Scrapes metrics from all ALPR services and infrastructure

global:
  scrape_interval: 15s      # How often to scrape targets
  evaluation_interval: 15s  # How often to evaluate rules
  scrape_timeout: 10s       # Timeout for each scrape

  external_labels:
    cluster: 'alpr-production'
    environment: 'jetson-orin-nx'

# Scrape configurations
scrape_configs:
  # ALPR Pilot (Edge Processing)
  # Runs on host machine (Jetson), accessible via host.docker.internal
  - job_name: 'alpr-pilot'
    static_configs:
      - targets: ['host.docker.internal:8001']
    metrics_path: '/metrics'
    scrape_interval: 5s  # Scrape frequently for real-time FPS/latency metrics

  # Kafka Consumer (Storage Service)
  # Runs in Docker, accessible via service name
  - job_name: 'kafka-consumer'
    static_configs:
      - targets: ['kafka-consumer:8002']
    metrics_path: '/metrics'
    scrape_interval: 10s

  # Alert Engine (Notification Service)
  # Runs in Docker, accessible via service name
  - job_name: 'alert-engine'
    static_configs:
      - targets: ['alert-engine:8003']
    metrics_path: '/metrics'
    scrape_interval: 10s

  # Elasticsearch Consumer (Search Indexer)
  # Runs in Docker, accessible via service name
  - job_name: 'elasticsearch-consumer'
    static_configs:
      - targets: ['elasticsearch-consumer:8004']
    metrics_path: '/metrics'
    scrape_interval: 10s

  # Query API (REST API)
  # Note: Query API doesn't expose /metrics endpoint currently
  # Uncomment when metrics endpoint is added
  # - job_name: 'query-api'
  #   static_configs:
  #     - targets: ['query-api:8000']
  #   metrics_path: '/metrics'
  #   scrape_interval: 10s

  # DLQ Consumer (Dead Letter Queue Handler)
  # Uncomment when dlq-consumer service is started
  # - job_name: 'dlq-consumer'
  #   static_configs:
  #     - targets: ['dlq-consumer:8005']
  #   metrics_path: '/metrics'
  #   scrape_interval: 10s

  # Metrics Consumer (Metrics Aggregator)
  # Uncomment when metrics-consumer service is started
  # - job_name: 'metrics-consumer'
  #   static_configs:
  #     - targets: ['metrics-consumer:8006']
  #   metrics_path: '/metrics'
  #   scrape_interval: 10s

  # cAdvisor (Container Metrics)
  # Provides CPU/RAM/network metrics for all Docker containers
  - job_name: 'cadvisor'
    static_configs:
      - targets: ['cadvisor:8080']
    metrics_path: '/metrics'
    scrape_interval: 10s

  # Prometheus Self-Monitoring
  # Monitor Prometheus itself
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
    metrics_path: '/metrics'
    scrape_interval: 30s

  # Node Exporter - Host system metrics (CPU, memory, disk, network)
  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']
    metrics_path: '/metrics'
    scrape_interval: 15s

  # TimescaleDB Postgres Exporter
  - job_name: 'timescaledb'
    static_configs:
      - targets: ['postgres-exporter:9187']
    metrics_path: '/metrics'
    scrape_interval: 30s

  # Kafka Exporter - Broker and consumer group metrics
  - job_name: 'kafka'
    static_configs:
      - targets: ['kafka-exporter:9308']
    metrics_path: '/metrics'
    scrape_interval: 30s

  # MinIO - Built-in Prometheus metrics
  - job_name: 'minio'
    static_configs:
      - targets: ['minio:9000']
    metrics_path: '/minio/v2/metrics/cluster'
    scrape_interval: 30s

  # MLflow - Model Registry and Experiment Tracking
  # Note: MLflow doesn't expose Prometheus metrics by default
  # This checks the /health endpoint for service availability
  - job_name: 'mlflow'
    static_configs:
      - targets: ['mlflow:5000']
    metrics_path: '/health'
    scrape_interval: 30s

  # Note: OpenSearch metrics are obtained via elasticsearch-consumer service
  # For direct OpenSearch metrics, install the prometheus-exporter plugin
