#!/usr/bin/env python3
"""
Prepare Training Dataset for YOLOv11
Splits data into train/val and creates YAML config
"""

import argparse
import shutil
import random
from pathlib import Path
from loguru import logger


def prepare_dataset(
    source_dir: str,
    output_dir: str = "datasets/florida_plates",
    train_split: float = 0.8,
    val_split: float = 0.2,
    seed: int = 42,
):
    """
    Prepare dataset for YOLOv11 training

    Args:
        source_dir: Source directory with images/ and labels/
        output_dir: Output dataset directory
        train_split: Training set ratio
        val_split: Validation set ratio
        seed: Random seed for reproducibility
    """
    source_dir = Path(source_dir)
    output_dir = Path(output_dir)

    logger.info(f"Preparing dataset from: {source_dir}")
    logger.info(f"Output directory: {output_dir}")

    # Verify source structure
    source_images = source_dir / "images"
    source_labels = source_dir / "labels"

    if not source_images.exists():
        logger.error(f"Images directory not found: {source_images}")
        return

    if not source_labels.exists():
        logger.error(f"Labels directory not found: {source_labels}")
        return

    # Get all image files
    image_files = sorted(source_images.glob("*.jpg")) + sorted(source_images.glob("*.png"))
    logger.info(f"Found {len(image_files)} images")

    if len(image_files) == 0:
        logger.error("No images found!")
        return

    # Filter to only images with labels
    valid_samples = []
    for img_path in image_files:
        label_path = source_labels / f"{img_path.stem}.txt"
        if label_path.exists():
            valid_samples.append(img_path.stem)
        else:
            logger.warning(f"No label for: {img_path.name}")

    logger.info(f"Valid samples (with labels): {len(valid_samples)}")

    if len(valid_samples) < 10:
        logger.error("Not enough samples! Need at least 10 images with labels.")
        return

    # Shuffle
    random.seed(seed)
    random.shuffle(valid_samples)

    # Split
    train_size = int(len(valid_samples) * train_split)
    train_samples = valid_samples[:train_size]
    val_samples = valid_samples[train_size:]

    logger.info(f"Train samples: {len(train_samples)}")
    logger.info(f"Val samples: {len(val_samples)}")

    # Create output structure
    train_images = output_dir / "train" / "images"
    train_labels = output_dir / "train" / "labels"
    val_images = output_dir / "val" / "images"
    val_labels = output_dir / "val" / "labels"

    for dir_path in [train_images, train_labels, val_images, val_labels]:
        dir_path.mkdir(parents=True, exist_ok=True)

    # Copy files
    logger.info("Copying training files...")
    for sample in train_samples:
        # Copy image
        src_img = source_images / f"{sample}.jpg"
        if not src_img.exists():
            src_img = source_images / f"{sample}.png"

        dst_img = train_images / src_img.name
        shutil.copy2(src_img, dst_img)

        # Copy label
        src_label = source_labels / f"{sample}.txt"
        dst_label = train_labels / f"{sample}.txt"
        shutil.copy2(src_label, dst_label)

    logger.info("Copying validation files...")
    for sample in val_samples:
        # Copy image
        src_img = source_images / f"{sample}.jpg"
        if not src_img.exists():
            src_img = source_images / f"{sample}.png"

        dst_img = val_images / src_img.name
        shutil.copy2(src_img, dst_img)

        # Copy label
        src_label = source_labels / f"{sample}.txt"
        dst_label = val_labels / f"{sample}.txt"
        shutil.copy2(src_label, dst_label)

    # Create YAML config
    yaml_path = output_dir / "florida_plates.yaml"

    yaml_content = f"""# Florida License Plates Dataset
# Generated by prepare_dataset.py

# Paths (relative to this file)
path: {output_dir.absolute()}
train: train/images
val: val/images

# Classes
names:
  0: license_plate

# Dataset info
nc: 1  # number of classes
"""

    with open(yaml_path, 'w') as f:
        f.write(yaml_content)

    logger.success("Dataset preparation complete!")
    logger.info(f"Dataset location: {output_dir}")
    logger.info(f"Config file: {yaml_path}")
    logger.info("")
    logger.info("Next steps:")
    logger.info(f"  1. Review the dataset in: {output_dir}")
    logger.info(f"  2. Train with: python3 tools/train_plate_detector.py --data {yaml_path}")


def main():
    parser = argparse.ArgumentParser(
        description="Prepare dataset for YOLOv11 training"
    )
    parser.add_argument(
        "source",
        help="Source directory with images/ and labels/"
    )
    parser.add_argument(
        "--output",
        default="datasets/florida_plates",
        help="Output dataset directory (default: datasets/florida_plates)"
    )
    parser.add_argument(
        "--train-split",
        type=float,
        default=0.8,
        help="Training set ratio (default: 0.8)"
    )
    parser.add_argument(
        "--val-split",
        type=float,
        default=0.2,
        help="Validation set ratio (default: 0.2)"
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=42,
        help="Random seed (default: 42)"
    )

    args = parser.parse_args()

    prepare_dataset(
        source_dir=args.source,
        output_dir=args.output,
        train_split=args.train_split,
        val_split=args.val_split,
        seed=args.seed,
    )


if __name__ == "__main__":
    main()
