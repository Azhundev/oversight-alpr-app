version: '3.8'

services:
  # ZooKeeper - Required for Kafka coordination
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    hostname: zookeeper
    container_name: alpr-zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-logs:/var/lib/zookeeper/log
    networks:
      - alpr-network
    restart: unless-stopped

  # Kafka Broker
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    hostname: kafka
    container_name: alpr-kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "9101:9101"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      # Transaction and log settings
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      # Performance tuning
      KAFKA_LOG_RETENTION_HOURS: 168  # 7 days
      KAFKA_LOG_SEGMENT_BYTES: 1073741824  # 1GB
      KAFKA_COMPRESSION_TYPE: gzip
    volumes:
      - kafka-data:/var/lib/kafka/data
    networks:
      - alpr-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Schema Registry - Confluent Schema Registry for event schema management
  schema-registry:
    image: confluentinc/cp-schema-registry:7.5.0
    hostname: schema-registry
    container_name: alpr-schema-registry
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'kafka:29092'
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      # Schema compatibility settings
      SCHEMA_REGISTRY_SCHEMA_COMPATIBILITY_LEVEL: backward
      # Performance tuning
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - alpr-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/subjects"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # Kafka UI - Web interface for managing Kafka
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: alpr-kafka-ui
    depends_on:
      - kafka
      - schema-registry
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: alpr-local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schema-registry:8081
    networks:
      - alpr-network
    restart: unless-stopped

  # TimescaleDB - PostgreSQL with time-series optimization
  timescaledb:
    image: timescale/timescaledb:latest-pg16
    container_name: alpr-timescaledb
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: alpr
      POSTGRES_PASSWORD: alpr_secure_pass
      POSTGRES_DB: alpr_db
    volumes:
      - timescaledb-data:/var/lib/postgresql/data
      - ./scripts/init_db.sql:/docker-entrypoint-initdb.d/init_db.sql
    networks:
      - alpr-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U alpr -d alpr_db"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Kafka Consumer - Consumes plate events and stores in TimescaleDB
  kafka-consumer:
    build:
      context: .
      dockerfile: core-services/storage/Dockerfile
    container_name: alpr-kafka-consumer
    depends_on:
      kafka:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
      timescaledb:
        condition: service_healthy
    environment:
      # Kafka configuration
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC: alpr.events.plates
      KAFKA_GROUP_ID: alpr-storage-consumer
      # Schema Registry configuration
      SCHEMA_REGISTRY_URL: http://schema-registry:8081
      USE_AVRO: "true"  # Set to "false" to use JSON deserialization
      # Database configuration
      DB_HOST: timescaledb
      DB_PORT: 5432
      DB_NAME: alpr_db
      DB_USER: alpr
      DB_PASSWORD: alpr_secure_pass
      # DLQ and Retry configuration
      MAX_RETRIES: "3"
      RETRY_DELAY_BASE: "2.0"
      PROCESSING_TIMEOUT: "30.0"
      ENABLE_DLQ: "true"
      DLQ_TOPIC: alpr.dlq
    volumes:
      - ./logs:/app/logs
    networks:
      - alpr-network
    restart: unless-stopped

  # Alert Engine - Real-time notifications based on configured rules
  alert-engine:
    build:
      context: .
      dockerfile: core-services/alerting/Dockerfile
    container_name: alpr-alert-engine
    depends_on:
      kafka:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    ports:
      - "8003:8003"  # Prometheus metrics
    environment:
      # Kafka configuration
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC: alpr.events.plates
      KAFKA_GROUP_ID: alpr-alert-engine
      # Schema Registry configuration
      SCHEMA_REGISTRY_URL: http://schema-registry:8081
      # Rules configuration
      RULES_CONFIG_PATH: /app/config/alert_rules.yaml
      # DLQ and Retry configuration
      MAX_RETRIES: "3"
      RETRY_DELAY_BASE: "2.0"
      PROCESSING_TIMEOUT: "30.0"
      ENABLE_DLQ: "true"
      DLQ_TOPIC: alpr.dlq
      # Notification secrets (set in .env file or pass via environment)
      SMTP_PASSWORD: "${SMTP_PASSWORD:-}"
      SLACK_WEBHOOK_URL: "${SLACK_WEBHOOK_URL:-}"
      WEBHOOK_TOKEN: "${WEBHOOK_TOKEN:-}"
      TWILIO_ACCOUNT_SID: "${TWILIO_ACCOUNT_SID:-}"
      TWILIO_AUTH_TOKEN: "${TWILIO_AUTH_TOKEN:-}"
    volumes:
      - ./config/alert_rules.yaml:/app/config/alert_rules.yaml:ro
      - ./logs:/app/logs
    networks:
      - alpr-network
    restart: unless-stopped

  # MinIO - S3-compatible object storage for plate crop images
  minio:
    image: minio/minio:latest
    container_name: alpr-minio
    ports:
      - "9000:9000"    # MinIO API
      - "9001:9001"    # MinIO Console
    environment:
      MINIO_ROOT_USER: alpr_minio
      MINIO_ROOT_PASSWORD: alpr_minio_secure_pass_2024
    command: server /data --console-address ":9001"
    volumes:
      - minio-data:/data
    networks:
      - alpr-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3

  # MinIO bucket initialization
  minio-init:
    image: minio/mc:latest
    container_name: alpr-minio-init
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      mc alias set minio http://minio:9000 alpr_minio alpr_minio_secure_pass_2024;
      mc mb --ignore-existing minio/alpr-plate-images;
      mc policy set download minio/alpr-plate-images;
      exit 0;
      "
    networks:
      - alpr-network

  # Query API - REST API for querying plate detection events
  query-api:
    build:
      context: .
      dockerfile: core-services/api/Dockerfile
    container_name: alpr-query-api
    depends_on:
      timescaledb:
        condition: service_healthy
    ports:
      - "8000:8000"
    environment:
      # Database configuration
      DB_HOST: timescaledb
      DB_PORT: 5432
      DB_NAME: alpr_db
      DB_USER: alpr
      DB_PASSWORD: alpr_secure_pass
      # MinIO configuration
      MINIO_ENDPOINT: minio:9000
      MINIO_ACCESS_KEY: alpr_minio
      MINIO_SECRET_KEY: alpr_minio_secure_pass_2024
      MINIO_BUCKET: alpr-plate-images
      # OpenSearch configuration
      OPENSEARCH_HOSTS: http://opensearch:9200
    networks:
      - alpr-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # ============================================================================
  # MONITORING STACK
  # ============================================================================

  # Prometheus - Metrics collection and storage
  prometheus:
    image: prom/prometheus:latest
    container_name: alpr-prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    ports:
      - "9090:9090"
    volumes:
      - ./core-services/monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    networks:
      - alpr-network
    restart: unless-stopped
    extra_hosts:
      - "host.docker.internal:host-gateway"
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Grafana - Metrics visualization and dashboards
  grafana:
    image: grafana/grafana:latest
    container_name: alpr-grafana
    depends_on:
      - prometheus
      - loki
    ports:
      - "3000:3000"
    environment:
      # Admin credentials
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: alpr_admin_2024
      # Server settings
      GF_SERVER_ROOT_URL: http://localhost:3000
      GF_SERVER_SERVE_FROM_SUB_PATH: false
      # Anonymous access (disable in production)
      GF_AUTH_ANONYMOUS_ENABLED: false
      # Provisioning
      GF_PATHS_PROVISIONING: /etc/grafana/provisioning
      # Performance
      GF_ANALYTICS_REPORTING_ENABLED: false
      GF_ANALYTICS_CHECK_FOR_UPDATES: false
    volumes:
      - grafana-data:/var/lib/grafana
      - ./core-services/monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./core-services/monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    networks:
      - alpr-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Loki - Log aggregation
  loki:
    image: grafana/loki:latest
    container_name: alpr-loki
    command: -config.file=/etc/loki/loki-config.yaml
    ports:
      - "3100:3100"
    volumes:
      - ./core-services/monitoring/loki/loki-config.yaml:/etc/loki/loki-config.yaml:ro
      - loki-data:/loki
    networks:
      - alpr-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3100/ready"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Promtail - Log shipper for Loki
  promtail:
    image: grafana/promtail:latest
    container_name: alpr-promtail
    depends_on:
      - loki
    command: -config.file=/etc/promtail/promtail-config.yaml
    volumes:
      - ./core-services/monitoring/promtail/promtail-config.yaml:/etc/promtail/promtail-config.yaml:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - ./logs:/logs:ro
    networks:
      - alpr-network
    restart: unless-stopped

  # cAdvisor - Container metrics exporter
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: alpr-cadvisor
    privileged: true
    devices:
      - /dev/kmsg:/dev/kmsg
    ports:
      - "8082:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    networks:
      - alpr-network
    restart: unless-stopped
    command:
      - '--housekeeping_interval=10s'
      - '--docker_only=true'
      - '--disable_metrics=percpu,sched,tcp,udp,disk,diskIO,hugetlb,referenced_memory,cpu_topology,resctrl'

  # ============================================================================
  # SEARCH & ANALYTICS
  # ============================================================================

  # OpenSearch - Full-text search and analytics engine
  opensearch:
    image: opensearchproject/opensearch:2.11.0
    container_name: alpr-opensearch
    environment:
      discovery.type: single-node
      DISABLE_SECURITY_PLUGIN: "true"
      OPENSEARCH_JAVA_OPTS: "-Xms512m -Xmx1g"  # Critical for Jetson
      bootstrap.memory_lock: "false"
    ports:
      - "9200:9200"
      - "9600:9600"
    volumes:
      - opensearch-data:/usr/share/opensearch/data
    networks:
      - alpr-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # OpenSearch Dashboards - Web UI for OpenSearch (optional)
  opensearch-dashboards:
    image: opensearchproject/opensearch-dashboards:2.11.0
    container_name: alpr-opensearch-dashboards
    depends_on:
      opensearch:
        condition: service_healthy
    ports:
      - "5601:5601"
    environment:
      OPENSEARCH_HOSTS: '["http://opensearch:9200"]'
      DISABLE_SECURITY_DASHBOARDS_PLUGIN: "true"
    networks:
      - alpr-network
    restart: unless-stopped
    profiles:
      - analytics  # Only start with: docker compose --profile analytics up

  # Elasticsearch Consumer - Kafka consumer that indexes events to OpenSearch
  elasticsearch-consumer:
    build:
      context: .
      dockerfile: core-services/search/Dockerfile
    container_name: alpr-elasticsearch-consumer
    depends_on:
      kafka:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
      opensearch:
        condition: service_healthy
    ports:
      - "8004:8004"  # Prometheus metrics
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC: alpr.events.plates
      KAFKA_GROUP_ID: alpr-elasticsearch-consumer
      SCHEMA_REGISTRY_URL: http://schema-registry:8081
      OPENSEARCH_HOSTS: http://opensearch:9200
      OPENSEARCH_INDEX_PREFIX: alpr-events
      OPENSEARCH_BULK_SIZE: "50"
      OPENSEARCH_FLUSH_INTERVAL: "5"
      AUTO_OFFSET_RESET: latest
      # DLQ and Retry configuration
      MAX_RETRIES: "3"
      RETRY_DELAY_BASE: "2.0"
      PROCESSING_TIMEOUT: "30.0"
      ENABLE_DLQ: "true"
      DLQ_TOPIC: alpr.dlq
    volumes:
      - ./logs:/app/logs
    networks:
      - alpr-network
    restart: unless-stopped

  # DLQ Consumer - Monitors dead letter queue for failed messages
  dlq-consumer:
    build:
      context: .
      dockerfile: core-services/dlq/Dockerfile
    container_name: alpr-dlq-consumer
    depends_on:
      kafka:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    ports:
      - "8005:8005"  # Prometheus metrics
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC: alpr.dlq
      KAFKA_GROUP_ID: alpr-dlq-consumer
      SCHEMA_REGISTRY_URL: http://schema-registry:8081
      AUTO_OFFSET_RESET: earliest  # Process all DLQ messages from beginning
      METRICS_PORT: "8005"
    volumes:
      - ./logs:/app/logs
    networks:
      - alpr-network
    restart: unless-stopped

  # Metrics Consumer - Consumes system metrics from Kafka and exposes for Prometheus
  metrics-consumer:
    build:
      context: .
      dockerfile: core-services/metrics/Dockerfile
    container_name: alpr-metrics-consumer
    depends_on:
      kafka:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    ports:
      - "8006:8006"  # Prometheus metrics
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC: alpr.metrics
      KAFKA_GROUP_ID: alpr-metrics-consumer
      SCHEMA_REGISTRY_URL: http://schema-registry:8081
      AUTO_OFFSET_RESET: latest  # Only consume new metrics
      METRICS_PORT: "8006"
    volumes:
      - ./logs:/app/logs
    networks:
      - alpr-network
    restart: unless-stopped

volumes:
  # Data persistence volumes
  zookeeper-data:
    driver: local
  zookeeper-logs:
    driver: local
  kafka-data:
    driver: local
  timescaledb-data:
    driver: local
  minio-data:
    driver: local

  # Monitoring stack volumes
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
  loki-data:
    driver: local

  # Search & analytics volumes
  opensearch-data:
    driver: local

networks:
  alpr-network:
    driver: bridge
